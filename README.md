# AI 기반 게임 매크로 프로그램 구현 계획

**이 문서는 게임 화면을 인식하고 캐릭터 간의 거리 변수에 따라 자동으로 버프를 제공하는 매크로 프로그램의 전체 구현 계획을 담고 있습니다. 매크로 방지 프로그램에 걸리지 않기 위해 커널 수준의 키보드 입력을 사용하는 것이 핵심 목표입니다.**

---
## 결과물
<img src="Result.gif" width="300" height="200"/>

---
## 과정
### 1단계: AI 기반 게임 화면 인식 및 객체 분류

* **목표:** AI를 활용해 게임 화면 속 내 캐릭터와 동료 캐릭터를 정확하게 인식하고 분류하는 것임.
* **기술:** **객체 탐지(Object Detection)** 기술이 필요해 실시간 탐지에 최적화된 **YOLO(You Only Look Once)** 모델을 사용했음.
---
#### 데이터 준비

* **스크린샷 수집:** 다양한 게임 상황(전투, 이동 등)에서 수백 장의 스크린샷을 수집했음. **`screenshots.py`**
    * 스크린샷 수집을 다시 진행 할때  파일이 덮어씌워지는 문제를 해결하기 위해 **`rename_files.py`** 스크립트를 사용했음.
* **데이터 라벨링:** 수작업으로 내 캐릭터(`my_character`)와 동료 캐릭터(`ally_character`) 영역에 바운딩 박스를 표시했음.
    * **LabelImg** 프로그램을 활용했으며, 라벨링 프로그램의 변수 형식 오류를 해결하는 과정이 있었음. [해결 참조](https://velog.io/@hglee_gun/Data-Labeling)
    * 학습용 이미지와 검증용 이미지 폴더 구조화 작업 중 **절대 경로**가 아닌 **상대 경로**로 데이터셋 경로를 설정하는 것이 중요했음.
    * **데이터 라벨링**과 **세그멘테이션**의 차이를 명확히 이해했음.
        |구분|	데이터 라벨링 (객체 탐지)  |세그멘테이션 (인스턴스)
        |:---|---:|:---:|
        |목표|	객체의 위치를 사각형으로 감지  |객체의 정확한 모양을 픽셀 단위로 분할
        |결과물|	(x, y, w, h) 형식의 사각형 좌표|객체 형태를 따라 픽셀 단위로 생성된 마스크
        |세밀함|	낮음 (객체의 대략적인 위치 파악) |매우 높음 (픽셀 단위의 정교한 경계)
        |사용 예시|	자율주행차에서 보행자 위치 파악, 게임 캐릭터 인식|의료 영상 분석(암세포 영역 분할), 배경 제거 앱
---
#### 학습 및 추론

* **모델 학습:** 수집된 데이터를 기반으로 YOLO 모델을 학습시켰음.
    * 100장의 데이터로는 인식률이 낮아 290장으로 학습을 진행했고, 실제 성능이 꽤 괜찮아졌음.
    * 수작업의 한계로 인해 더 많은 이미지를 사용하지 못했으며, **스테이블 디퓨전의 SAM**을 활용한 자동 라벨링을 고려했지만 포기했음.
* **프로그램 실행:** `screenshots.py`를 응용해 프로그램 실행 시 실시간으로 게임 화면을 캡처하고 객체 위치 좌표를 추출했음.

---

## 2단계: 버프 기능 구현 (거리 계산)

- **좌표 활용:** 화면 인식 단계에서 얻은 캐릭터 좌표를 이용하여 버프 제공 여부 결정
- **거리 계산:** 
  - 바운딩 박스 중심 좌표 간 거리 계산
  - 피타고라스 정리 활용:  
    `distance = sqrt((x2 - x1)^2 + (y2 - y1)^2)`
  - 픽셀 단위로 정확한 거리 계산

  - 버프 조건
    - 계산된 거리가 미리 정해진 임계값보다 작을 경우
    - 버프 재사용 대기 시간이 아닐 경우
---

## 3단계: 키보드 입력

- **목표:** 매크로 방지 프로그램 감지를 피하기 위해 OS의 API를 직접 호출
- **구현 상세:**
  - 파이썬에서 AI 및 게임 로직 수행
  - C++ 모듈로 커널 수준 키보드 입력 처리 (ctypes 또는 Pybind11 사용)

### 최소 기능으로 제작한 프로젝트로 간단한 테스트 외 실사용하지 않음.
